{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'flask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflask\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Flask, request, jsonify, render_template\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'flask'"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import openai\n",
    "\n",
    "\n",
    "class Chatbot:\n",
    "    def __init__(self, file_paths, api_key):\n",
    "        self.file_paths = file_paths\n",
    "        openai.api_key = api_key\n",
    "        self.knowledge_base = self.load_data()\n",
    "        self.documents = self.prepare_documents()\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.tfidf_matrix = self.vectorizer.fit_transform(self.documents)\n",
    "        self.full_documents = self.knowledge_base\n",
    "        self.cve_index = self.create_cve_index()\n",
    "        self.conversation_history = []\n",
    "\n",
    "    def load_data(self):\n",
    "        all_data = []\n",
    "        for file_path in self.file_paths:\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                data = json.load(file)\n",
    "                all_data.extend(data)\n",
    "        return all_data\n",
    "\n",
    "    def concatenate_text(self, json_obj):\n",
    "        fields = ['CVE_ID', 'Assigner', 'Description']\n",
    "        concatenated_text = ' '.join(str(json_obj[field]) for field in fields if field in json_obj)\n",
    "        return concatenated_text\n",
    "\n",
    "    def prepare_documents(self):\n",
    "        return [self.concatenate_text(item) for item in self.knowledge_base]\n",
    "\n",
    "    def create_cve_index(self):\n",
    "        cve_index = {}\n",
    "        for idx, item in enumerate(self.knowledge_base):\n",
    "            cve_id = item.get('CVE_ID')\n",
    "            if cve_id:\n",
    "                cve_index[cve_id] = idx\n",
    "        return cve_index\n",
    "\n",
    "    def answer_question(self, query):\n",
    "        query_words = query.split()\n",
    "        found_documents = []\n",
    "\n",
    "        # Check if any word in the query is a CVE_ID\n",
    "        for word in query_words:\n",
    "            if word in self.cve_index:\n",
    "                index = self.cve_index[word]\n",
    "                found_documents.append(self.full_documents[index])\n",
    "\n",
    "        # If any CVE_ID is found, return the corresponding documents\n",
    "        if found_documents:\n",
    "            return found_documents\n",
    "\n",
    "        # If no CVE_ID is found, proceed with TF-IDF similarity search\n",
    "        similarity_scores = np.zeros(len(self.documents))\n",
    "\n",
    "        for word in query_words:\n",
    "            query_vec = self.vectorizer.transform([word])\n",
    "            similarities = cosine_similarity(query_vec, self.tfidf_matrix)[0]\n",
    "            similarity_scores += similarities\n",
    "\n",
    "        top_indices = np.argsort(similarity_scores)[-10:][::-1]\n",
    "        top_documents = [self.full_documents[i] for i in top_indices]\n",
    "        return top_documents\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Initialize the chatbot with multiple files\n",
    "file_paths = [\n",
    "    'nvdcve-1.1-recent_updated.json',\n",
    "    'nvdcve-1.1-modified_updated.json',\n",
    "    'nvdcve-1.1-2024_updated.json',\n",
    "    'nvdcve-1.1-2023_updated.json',\n",
    "    'nvdcve-1.1-2022_updated.json',\n",
    "    # Add more files if needed\n",
    "]\n",
    "\n",
    "chatbot = Chatbot(file_paths, api_key='your-api-key')\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/ask', methods=['POST'])\n",
    "def ask_question():\n",
    "    question = request.form['question']\n",
    "    answer = chatbot.answer_question(question)\n",
    "    return jsonify(answer=answer)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
